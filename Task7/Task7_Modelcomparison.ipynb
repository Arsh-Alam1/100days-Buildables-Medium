{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison & Evaluation - House Prices Dataset\n",
    "\n",
    "In this notebook, I will train and compare three models on the Kaggle House Prices dataset:\n",
    "- Linear Regression\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "\n",
    "I will evaluate them using MAE, RMSE, and R², and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Fill missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"int64\", \"float64\"]:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"TotalBsmtSF\", \"FullBath\"]\n",
    "categorical_features = [\"Neighborhood\", \"HouseStyle\"]\n",
    "target = \"SalePrice\"\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, [\"GrLivArea\", \"TotalBsmtSF\"]),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"Pipeline\": pipeline,\n",
    "        \"Predictions\": y_pred\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).drop(columns=[\"Pipeline\", \"Predictions\"])\n",
    "results_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"MAE\", \"RMSE\", \"R2\"]\n",
    "results_melted = results_df.melt(id_vars=\"Model\", value_vars=metrics, var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"Metric\", y=\"Value\", hue=\"Model\", data=results_melted)\n",
    "plt.title(\"Model Comparison Across Metrics\")\n",
    "plt.savefig(\"model_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(results, key=lambda x: x[\"R2\"])\n",
    "print(f\"Best Model: {best_model['Model']} (R² = {best_model['R2']:.4f})\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=best_model[\"Predictions\"], alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Actual SalePrice\")\n",
    "plt.ylabel(\"Predicted SalePrice\")\n",
    "plt.title(f\"Predicted vs Actual SalePrice ({best_model['Model']})\")\n",
    "plt.savefig(\"best_model_scatter.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- In my results, the Random Forest Regressor performed the best. I think the reason is that it uses many decision trees together, so it can learn complex patterns in the data without overfitting too much. Linear Regression was simple but couldn’t handle the non-linear parts of the data. The Decision Tree was better but it overfit a bit. Random Forest was a good balance.?\n",
    "-Linear Regression was the fastest and easiest to understand, but not very accurate.Decision Tree was more accurate and easy to explain (since you can follow the tree), but it overfit the training data.
Random Forest gave the best accuracy, but it was slower and harder to explain since it’s made of many trees.?\n",
    "- Adding more useful features or combining features (like total square footage).Doing hyperparameter tuning, for example changing the depth of trees or the number of trees in Random Forest.Using cross-validation instead of just one train-test split to get more reliable results.
Trying other models like Ridge, Lasso, or boosting methods (XGBoost, LightGBM) which usually perform even better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


